# ðŸ“„ DocuFlow â€“ Modular RAG MVP

**DocuFlow** is a small but complete **Retrieval-Augmented Generation (RAG)** application.
It demonstrates how to build a **clean, modular, and deployable** RAG pipeline â€” not just another â€œchat with your PDFsâ€ demo.

---

## ðŸš€ Features

* **Document Q\&A** â€“ upload PDFs/DOCs/TXT, ask questions.
* **Document Analysis** â€“ extract metadata (title, authors, sentiment, etc.).
* **Document Comparison** â€“ page-by-page differences between two docs.
* **Multi-document Support** â€“ index multiple files and chat across them.
* **Configurable LLMs** â€“ OpenAI, Groq, or Google Gemini via `config.yaml`.
* **Deployment Ready** â€“ Dockerized, CI/CD pipeline, AWS ECS Fargate deploy.

---

## ðŸ§© Architecture

```mermaid
flowchart LR
  A[Upload Documents] --> B[Ingestion Layer]
  B --> C[FAISS Index - Sessionized]
  C --> D[Retriever - MMR / Context Compression]
  D --> E[LLM Orchestration - Prompt Templates]
  E --> F[Answer / Compare / Analysis]
  F --> G[FastAPI Endpoints / UI]
  G --> H[Deployment - Docker + GitHub Actions + ECS Fargate]
```

---

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ api/                  # FastAPI entrypoints
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_ingestion/  # File saving, chunking, FAISS manager
â”‚   â”œâ”€â”€ document_chat/       # Conversational RAG chains
â”‚   â”œâ”€â”€ document_compare/    # Page-by-page comparison
â”‚   â”œâ”€â”€ document_analyzer/   # Metadata extraction
â”‚   â””â”€â”€ multi_document_chat/ # Multi-file retrievers
â”œâ”€â”€ prompt/               # Prompt templates
â”œâ”€â”€ utils/                # Config loader, file I/O, helpers
â”œâ”€â”€ config/               # config.yaml (embeddings/LLMs)
â”œâ”€â”€ logger/               # Structlog-based JSON logging
â”œâ”€â”€ .github/workflows/    # CI/CD pipelines (tests + deploy)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ”§ Tech Stack

* **Backend**: FastAPI
* **Vector Store**: FAISS
* **LLMs**: OpenAI GPT, Groq, Google Gemini (configurable)
* **Infra**: Docker, GitHub Actions, AWS ECS Fargate
* **Logging**: Structlog + CloudWatch

---

## âš¡ Usage

### 1. Run Locally

```bash
git clone https://github.com/<your-username>/docuflow.git
cd docuflow

# Create venv
python -m venv .venv
source .venv/bin/activate

# Install deps
pip install -r requirements.txt

# Set env vars (example)
export OPENAI_API_KEY=your_key
export LLM_PROVIDER=openai
export FAISS_BASE=faiss_index
export UPLOADED_BASE=data

# Run app
uvicorn api.main:app --reload --host 0.0.0.0 --port 8080
```

### 2. Endpoints

* **Health check** â†’ `GET /health`
* **Analyze document** â†’ `POST /analyze`
* **Compare two docs** â†’ `POST /compare`
* **Index documents** â†’ `POST /chat/index`
* **Query documents** â†’ `POST /chat/query`

### 3. Example (curl)

```bash
# Build index
curl -X POST "http://localhost:8080/chat/index" \
  -F "files=@./sample.pdf"

# Query
curl -X POST "http://localhost:8080/chat/query" \
  -F "question=What are the key points?" \
  -F "session_id=<returned-session-id>"
```

---

## ðŸ“¦ Deployment

### CI/CD Workflow

1. **Push to main**
2. GitHub Actions runs unit tests (`ci.yml`).
3. On success, build Docker image and push to ECR (`aws.yml`).
4. Deploy updated task definition to AWS ECS Fargate.

```mermaid
flowchart LR
  A[Push Code] --> B[Run Unit Tests]
  B -->|Pass| C[Build & Push Docker Image]
  C --> D[Update ECS Task Definition]
  D --> E[Deploy ECS Service]
```
